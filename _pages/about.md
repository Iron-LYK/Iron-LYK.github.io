---
permalink: /
title: "Greetings! ğŸ˜†"
excerpt: "Homepage"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Welcome to my website!

I am a third-year PhD student in the Sun Yat-sen University's Master-Doctor combined program, supervised by [Guang Tan](https://scholar.google.com/citations?hl=zh-CN&user=JerZls4AAAAJ&view_op=list_works&sortby=pubdate) and [Chao Gou](https://scholar.google.com/citations?user=_0ad79AAAAAJ&hl=en). 

Since June 2024, I have been honored to be a visiting Ph.D at [MMLab](https://mmlab.ie.cuhk.edu.hk/people.html), CUHK, under the supervision of Prof. [Tianfan Xue](https://tianfan.info/).

My research interests primarily focus on video generation and 3D Reconstruction. I am open to collaboration and welcome further discussions if you are interested in my research.<br />


   
ğŸ”¥ News ğŸ”¥
----- 
**âˆ™** [2025.12] ğŸŒŸğŸŒŸ Our new work, ReCamDriving, is released! Check it out via [here](https://recamdriving.github.io/).<br />
**âˆ™** [2025.10] ğŸŒŸğŸŒŸ Our new work, DynamicTree, is released! Check it out via [here](https://dynamictree-dev.github.io/DynamicTree.github.io/).<br />
**âˆ™** [2025.10] ğŸ‰ğŸ‰ One paper is accepted to PR 2025<br />
**âˆ™** [2025.07] ğŸ‰ğŸ‰ One paper is accepted to ICCV 2025<br />
**âˆ™** [2024.12] ğŸ‰ğŸ‰ One paper is accepted to AAAI 2025<br />
**âˆ™** [2024.11] ğŸ‰ğŸ‰ One paper is accepted to ESWA 2025<br />
**âˆ™** [2023.11] ğŸ‰ğŸ‰ One paper is accepted to IJCV 2024<br /> 

ğŸ“‘ Selected PublicationsÂ 
-----
<style>
  .pub-item {
    display: flex;
    /* ç§»é™¤ align-items: flex-startï¼Œè®©å·¦å³ä¸¤è¾¹é«˜åº¦è‡ªåŠ¨æ‹‰ä¼¸å¯¹é½ */
    margin-bottom: 25px;
    background-color: #fff; /* ç¡®ä¿èƒŒæ™¯è‰²ç»Ÿä¸€ï¼Œé˜²æ­¢ç¼éš™ */
  }
  
  .pub-item img {
    margin-right: 15px;
    width: 160px;       /* å®½åº¦å›ºå®š */
    height: 100%;       /* é«˜åº¦å¼ºåˆ¶å¡«æ»¡çˆ¶å®¹å™¨ï¼Œå³ä¸å³ä¾§æ–‡å­—ç­‰é«˜ */
    object-fit: cover;  /* å…³é”®å±æ€§ï¼šä¿æŒå›¾ç‰‡æ¯”ä¾‹è£å‰ªï¼Œé˜²æ­¢å›¾ç‰‡è¢«æ‹‰æ‰ */
    border-radius: 4px; /* ç¨å¾®åŠ ä¸€ç‚¹åœ†è§’æ›´ç¾è§‚ï¼Œå¯é€‰ */
  }

  /* å³ä¾§å†…å®¹å®¹å™¨ */
  .pub-content {
    display: flex;
    flex-direction: column;
    justify-content: space-between; /* è®©å†…å®¹åœ¨å‚ç›´æ–¹å‘å‡åŒ€åˆ†å¸ƒ */
    width: 100%;
  }

  .pub-item h3 {
    margin-top: 0;
    margin-bottom: 5px;
  }
  
  .pub-item p {
    line-height: 1.3; /* ç¨å¾®å¢åŠ è¡Œé«˜ï¼Œé˜…è¯»æ›´èˆ’é€‚ */
    font-size: small;
    margin: 0;
  }

  /* æ–°å¢çš„ä¸€å¥è¯æè¿°æ ·å¼ */
  .pub-desc {
    margin-top: 8px !important;
    margin-bottom: 8px !important;
    color: #555;
    font-style: italic;
    background-color: #f7f9fa;
    padding: 5px 8px;
    border-left: 3px solid #ccc;
    font-size: 0.9em !important;
  }

  .pub-divider {
    border: none;
    border-top: 1.5px solid #ccc;
    margin: 20px 0;
  }
</style>

<div class="pub-item">
  <img src="https://recamdriving.github.io/static/images/teaser.png">
  <div class="pub-content">
    <h3>ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation</h3>
    <p>
      <strong><u>Yaokun Li</u></strong>, Shuaixian Wang, Mantang Guo, Jiehui Huang, Taojun Ding, Mu Hu, Kaixuan Wang, Shaijie Shen, Guang Tan<br>
      <span style="display:inline-block; margin:6px 0;">arXiv Preprint, 2025</span>
    </p>
    <p class="pub-desc">
      A novel framework for generating driving videos controlled by camera trajectories without relying on LiDAR data.
    </p>
    <p>
      <a href="https://recamdriving.github.io/">Project</a> |
      <a href="https://arxiv.org/abs/2512.03621">Paper</a> |
      <a href="https://github.com/Iron-LYK/ReCamDriving">Code</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/FDEP.png">
  <div class="pub-content">
    <h3>Rethinking Infrared Small Target Detection: A Foundation-Driven Efficient Paradigm</h3>
    <p>
      Chuang Yu, Jinmiao Zhao, Yunpeng Liu, <strong><u>Yaokun Li</u></strong>, Xiujun Shu, Yuanhao Feng, Bo Wang, Yimian Dai, Xiangyu Yue<br>
      <span style="display:inline-block; margin:6px 0;">arXiv Preprint, 2025</span>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://arxiv.org/pdf/2512.05511">Paper</a> |
      <a href="https://github.com/YuChuang1205/FDEP-Framework">Code</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/DynamicTree.gif">
  <div class="pub-content">
    <h3>DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum</h3>
    <p>
      <strong><u>Yaokun Li</u></strong>, Lihe Ding, Xiao Chen, Guang Tan, Tianfan Xue<br>
      <span style="display:inline-block; margin:6px 0;">arXiv Preprint, 2025</span>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://dynamictree-dev.github.io/DynamicTree.github.io/">Project</a> |
      <a href="https://arxiv.org/abs/2510.22213">Paper</a> |
      <a href="https://github.com/Iron-LYK/DynamicTree">Code</a> |
      <a href="https://github.com/Iron-LYK/DynamicTree">Data</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/copart.gif">
  <div class="pub-content">
    <h3>From One to More: Contextual Part Latents for 3D Generation</h3>
    <p>
      Shaocong Dong*, Lihe Ding*, Xiao Chen, <strong><u>Yaokun Li</u></strong>, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim, Chenjian Gao, Zhanpeng Huang, Zibin Wang, Tianfan Xueâ€ , Dan Xuâ€ <br>
      <strong style="display:inline-block; margin:6px 0;">ICCV 2025</strong>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://hkdsc.github.io/project/copart/">Project</a> |
      <a href="https://arxiv.org/abs/2507.08772">Paper</a> |
      <a href="https://github.com/hkdsc/copart">Code</a> |
      <a href="https://huggingface.co/datasets/dscdyc/partverse/tree/main">Data</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/ID-NeRF.png">
  <div class="pub-content">
    <h3>ID-NeRF: Indirect Diffusion-Guided Neural Radiance Fields for Generalizable View Synthesis</h3>
    <p>
      <strong><u>Yaokun Li</u></strong>, Shuaixian Wang, Guang Tan<br>
      <strong style="display:inline-block; margin:6px 0;">ESWA 2025</strong>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S095741742402935X">Paper</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/CIT.png">
  <div class="pub-content">
    <h3>Cascaded Iterative Transformer for Jointly Predicting Facial Landmark, Occlusion Probability and Head Pose</h3>
    <p>
      <strong><u>Yaokun Li</u></strong>, Guang Tan, Chao Gou<br>
      <strong style="display:inline-block; margin:6px 0;">IJCV 2024</strong>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://doi.org/10.1007/s11263-023-01935-2">Paper</a> |
      <a href="https://github.com/Iron-LYK/CIT">Code</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/PIT.png">
  <div class="pub-content">
    <h3>PIT: Progressive Interaction Transformer for Pedestrian Crossing Intention Prediction</h3>
    <p>
      Yuchen Zhou, Guang Tan, Rui Zhong, <strong><u>Yaokun Li</u></strong>, Chao Gou<br>
      <strong style="display:inline-block; margin:6px 0;">TITS 2023</strong>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://ieeexplore.ieee.org/abstract/document/10247098">Paper</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

<div class="pub-item">
  <img src="../images/paper_teasers/MS-GCN.png">
  <div class="pub-content">
    <h3>MS-GCN: Multi-Stream Graph Convolution Network for Driver Head Pose Estimation</h3>
    <p>
      <strong><u>Yaokun Li</u></strong>, Yuezhao Yu, Yuliang Liu, Chao Gou<br>
      <strong style="display:inline-block; margin:6px 0;">ITSC 2022</strong>
    </p>
    <p class="pub-desc">
      Wait for your one-sentence description here.
    </p>
    <p>
      <a href="https://ieeexplore.ieee.org/abstract/document/9922277">Paper</a>
    </p>
  </div>
</div>
<hr class="pub-divider">

ğŸ† Awards 
----- 
âˆ™ \(2019\) China National Scholarship<br /> 
âˆ™ \(2020\) Polytechnic Youth Top Ten Students<br /> 
âˆ™ \(2022\) Honorable mention in HACKPKU 2022<br /> 
âˆ™ \(2023\) Third Prize of 2023 "Huawei Cup" National Graduate Student Mathematical Modeling Competition<br /> 




ğŸ“ Academic Service 
----- 
Reviewer:<br /> 
âˆ™ Conference Reviewer: CVPR, ECCV, AAAI, ...<br /> 
âˆ™ Journal Reviewer: IJCV, TCSVT, PR, ...S<br /> 



ğŸ“– Teaching 
----- 
âˆ™ Teaching Assistant: IERG4190-IEMS5707 Multimedia Coding and Processing, CUHK, 2024R2 
âˆ™ Teaching Assistant: ISE3111 Pattern Recognition & Machine Learning, SYSU, 2022 Fall 


ğŸ˜» My Hobbies
----- 
ğŸƒâ€â™‚ï¸ ğŸ€ ğŸ‹ ğŸ§ ğŸ“· ...
